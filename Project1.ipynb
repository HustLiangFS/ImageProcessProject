{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread, imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(f):\n",
    "    return  pickle.load(f, encoding='latin1')\n",
    "    \n",
    "def load_CIFAR_batch(filename):\n",
    "    \"\"\" load single batch of cifar \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = load_pickle(f)\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "        Y = np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "def load_CIFAR10(ROOT):\n",
    "    \"\"\" load all of cifar \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)    \n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000,)\n",
      "(10000, 32, 32, 3)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "xTrain, yTrain, xTest, yTest = load_CIFAR10(\"Datasets/cifar-10-batches-py/\")\n",
    "print(\"X_train:\", xTrain.shape)\n",
    "print(\"Y_train:\", yTrain.shape)\n",
    "print(\"X_test:\", xTest.shape)\n",
    "print(\"Y_test:\", yTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import data, exposure\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "def extract_features(mode, X_train, X_test):\n",
    "    if mode == \"RAW\":\n",
    "        X_train = X_train\n",
    "        X_test = X_test\n",
    "    elif mode == \"HOG\":\n",
    "        X_train = np.array([hog(rgb2gray(image), orientations=8, pixels_per_cell=(16, 16),\n",
    "                   cells_per_block=(1, 1)) for image in X_train])\n",
    "        X_test = np.array([hog(rgb2gray(image), orientations=8, pixels_per_cell=(16, 16),\n",
    "                   cells_per_block=(1, 1)) for image in X_test])\n",
    "    elif mode == \"LBP\":\n",
    "        X_train = np.array([local_binary_pattern(rgb2gray(image),P=1,R=2) for image in X_train])\n",
    "        X_test = np.array([local_binary_pattern(rgb2gray(image),P=1,R=2) for image in X_test])\n",
    "    elif mode == \"SIFT\":\n",
    "        # TODO: cv2 in my computer has some bugs. I need to rebuild it from source.\n",
    "#         gray= cv2.cvtColor(xTrain[0].astype(np.uint8),cv2.COLOR_BGR2GRAY)  \n",
    "#         sift = cv2.SIFT(200) \n",
    "#         kp = sift.detect(gray,None)  \n",
    "#         des = sift.compute(gray,kp)\n",
    "        pass\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def models(model_name, opt=None):\n",
    "    if model_name == \"knn\":\n",
    "        if opt is not None:\n",
    "            model = neighbors.KNeighborsClassifier(opt[\"k\"])\n",
    "        else:\n",
    "            model = neighbors.KNeighborsClassifier()\n",
    "    elif model_name == \"svm\":\n",
    "        model = svm.SVC()\n",
    "    elif model_name == \"lr\":\n",
    "        model = LogisticRegression()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: HOG, model: knn: 0.316 time: 0.30071091651916504\n",
      "features: HOG, model: svm: 0.278 time: 2.9465811252593994\n",
      "features: HOG, model: lr: 0.347 time: 0.14871549606323242\n",
      "features: LBP, model: knn: 0.192 time: 8.000333786010742\n",
      "features: LBP, model: svm: 0.215 time: 49.28135538101196\n",
      "features: LBP, model: lr: 0.133 time: 12.523408889770508\n",
      "features: RAW, model: knn: 0.266 time: 23.53723692893982\n",
      "features: RAW, model: svm: 0.106 time: 148.2321000099182\n",
      "features: RAW, model: lr: 0.207 time: 854.5061383247375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# subsample, just for a fast try\n",
    "xTrain = xTrain[:5000]\n",
    "Y_train = yTrain[:5000]\n",
    "xTest = xTest[:1000]\n",
    "Y_test = yTest[:1000]\n",
    "\n",
    "# features: hog\n",
    "X_train, X_test = extract_features(mode=\"HOG\", X_train=xTrain, X_test=xTest)\n",
    "# model: knn\n",
    "model = models(\"knn\")\n",
    "start = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"features: HOG, model: knn:\", model.score(X_test, Y_test), \"time:\", time.time()-start)\n",
    "# model: svm\n",
    "model = models(\"svm\")\n",
    "start = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"features: HOG, model: svm:\", model.score(X_test, Y_test), \"time:\", time.time()-start)\n",
    "# model: lr\n",
    "model = models(\"lr\")\n",
    "start = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"features: HOG, model: lr:\", model.score(X_test, Y_test), \"time:\", time.time()-start)\n",
    "\n",
    "# features: LBP\n",
    "X_train, X_test = extract_features(mode=\"LBP\", X_train=xTrain, X_test=xTest)\n",
    "# model: knn\n",
    "model = models(\"knn\")\n",
    "start = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"features: LBP, model: knn:\", model.score(X_test, Y_test), \"time:\", time.time()-start)\n",
    "# model: svm\n",
    "model = models(\"svm\")\n",
    "start = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"features: LBP, model: svm:\", model.score(X_test, Y_test), \"time:\", time.time()-start)\n",
    "# model: lr\n",
    "model = models(\"lr\")\n",
    "start = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"features: LBP, model: lr:\", model.score(X_test, Y_test), \"time:\", time.time()-start)\n",
    "\n",
    "# features: RAW\n",
    "X_train, X_test = extract_features(mode=\"RAW\", X_train=xTrain, X_test=xTest)\n",
    "# model: knn\n",
    "model = models(\"knn\")\n",
    "start = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"features: RAW, model: knn:\", model.score(X_test, Y_test), \"time:\", time.time()-start)\n",
    "# model: svm\n",
    "model = models(\"svm\")\n",
    "start = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"features: RAW, model: svm:\", model.score(X_test, Y_test), \"time:\", time.time()-start)\n",
    "# model: lr\n",
    "model = models(\"lr\")\n",
    "start = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"features: RAW, model: lr:\", model.score(X_test, Y_test), \"time:\", time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: just try different hyparameters and try cross validation to choose better hyparameters\n",
    "# TODO: use all data. Now I only use 1/10 data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
