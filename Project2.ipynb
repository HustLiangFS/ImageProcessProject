{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread, imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(f):\n",
    "    return  pickle.load(f, encoding='latin1')\n",
    "    \n",
    "def load_CIFAR_batch(filename):\n",
    "    \"\"\" load single batch of cifar \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = load_pickle(f)\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "        Y = np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "def load_CIFAR10(ROOT):\n",
    "    \"\"\" load all of cifar \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)    \n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (50000, 32, 32, 3)\n",
      "Y_train: (50000,)\n",
      "X_test: (10000, 32, 32, 3)\n",
      "Y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "xTrain, yTrain, xTest, yTest = load_CIFAR10(\"Datasets/cifar-10-batches-py/\")\n",
    "print(\"X_train:\", xTrain.shape)\n",
    "print(\"Y_train:\", yTrain.shape)\n",
    "print(\"X_test:\", xTest.shape)\n",
    "print(\"Y_test:\", yTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10(Dataset):\n",
    "    def __init__(self, data, label, data_num):\n",
    "        super(Cifar10, self).__init__()\n",
    "        self.data_num = data_num\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.MEAN = [125.306918046875, 122.950394140625, 113.86538318359375]\n",
    "        self.STD = [62.993219278136884, 62.08870764001421, 66.70489964063091]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 归一化\n",
    "        data = self.data[index].astype(np.float32)\n",
    "        data[:, :, 0] = (data[:, :, 0] - self.MEAN[0]) / self.STD[0]\n",
    "        data[:, :, 1] = (data[:, :, 1] - self.MEAN[1]) / self.STD[1]\n",
    "        data[:, :, 2] = (data[:, :, 2] - self.MEAN[2]) / self.STD[2]\n",
    "        label = self.label[index]\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(3072, 3072),\n",
    "            nn.BatchNorm1d(3072),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        output = self.model(data)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 50000\n",
    "NUM_TEST = 10000\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "trainDataset = Cifar10(xTrain, yTrain, NUM_TRAIN)\n",
    "testDataset = Cifar10(xTest, yTest, NUM_TEST)\n",
    "trainLoader = DataLoader(dataset=trainDataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
    "testLoader = DataLoader(dataset=testDataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
    "model = MLP()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.0069, Train Acc: 0.3698, Test Loss: 0.0060, Test Acc: 0.4548\n",
      "Epoch [2/50], Train Loss: 0.0061, Train Acc: 0.4448, Test Loss: 0.0056, Test Acc: 0.4820\n",
      "Epoch [3/50], Train Loss: 0.0057, Train Acc: 0.4763, Test Loss: 0.0054, Test Acc: 0.5038\n",
      "Epoch [4/50], Train Loss: 0.0055, Train Acc: 0.4967, Test Loss: 0.0053, Test Acc: 0.5140\n",
      "Epoch [5/50], Train Loss: 0.0053, Train Acc: 0.5145, Test Loss: 0.0052, Test Acc: 0.5249\n",
      "Epoch [6/50], Train Loss: 0.0052, Train Acc: 0.5239, Test Loss: 0.0050, Test Acc: 0.5352\n",
      "Epoch [7/50], Train Loss: 0.0050, Train Acc: 0.5402, Test Loss: 0.0050, Test Acc: 0.5436\n",
      "Epoch [8/50], Train Loss: 0.0049, Train Acc: 0.5515, Test Loss: 0.0049, Test Acc: 0.5503\n",
      "Epoch [9/50], Train Loss: 0.0048, Train Acc: 0.5613, Test Loss: 0.0049, Test Acc: 0.5531\n",
      "Epoch [10/50], Train Loss: 0.0047, Train Acc: 0.5729, Test Loss: 0.0048, Test Acc: 0.5606\n",
      "Epoch [11/50], Train Loss: 0.0046, Train Acc: 0.5829, Test Loss: 0.0048, Test Acc: 0.5611\n",
      "Epoch [12/50], Train Loss: 0.0045, Train Acc: 0.5905, Test Loss: 0.0048, Test Acc: 0.5635\n",
      "Epoch [13/50], Train Loss: 0.0044, Train Acc: 0.5995, Test Loss: 0.0047, Test Acc: 0.5670\n",
      "Epoch [14/50], Train Loss: 0.0043, Train Acc: 0.6086, Test Loss: 0.0047, Test Acc: 0.5668\n",
      "Epoch [15/50], Train Loss: 0.0042, Train Acc: 0.6221, Test Loss: 0.0047, Test Acc: 0.5743\n",
      "Epoch [16/50], Train Loss: 0.0041, Train Acc: 0.6281, Test Loss: 0.0047, Test Acc: 0.5748\n",
      "Epoch [17/50], Train Loss: 0.0040, Train Acc: 0.6359, Test Loss: 0.0046, Test Acc: 0.5766\n",
      "Epoch [18/50], Train Loss: 0.0039, Train Acc: 0.6464, Test Loss: 0.0047, Test Acc: 0.5782\n",
      "Epoch [19/50], Train Loss: 0.0038, Train Acc: 0.6518, Test Loss: 0.0047, Test Acc: 0.5718\n",
      "Epoch [20/50], Train Loss: 0.0037, Train Acc: 0.6643, Test Loss: 0.0047, Test Acc: 0.5782\n",
      "Epoch [21/50], Train Loss: 0.0036, Train Acc: 0.6688, Test Loss: 0.0047, Test Acc: 0.5838\n",
      "Epoch [22/50], Train Loss: 0.0035, Train Acc: 0.6764, Test Loss: 0.0047, Test Acc: 0.5764\n",
      "Epoch [23/50], Train Loss: 0.0034, Train Acc: 0.6856, Test Loss: 0.0047, Test Acc: 0.5893\n",
      "Epoch [24/50], Train Loss: 0.0033, Train Acc: 0.6955, Test Loss: 0.0047, Test Acc: 0.5835\n",
      "Epoch [25/50], Train Loss: 0.0032, Train Acc: 0.7027, Test Loss: 0.0047, Test Acc: 0.5890\n",
      "Epoch [26/50], Train Loss: 0.0032, Train Acc: 0.7084, Test Loss: 0.0047, Test Acc: 0.5892\n",
      "Epoch [27/50], Train Loss: 0.0031, Train Acc: 0.7201, Test Loss: 0.0048, Test Acc: 0.5911\n",
      "Epoch [28/50], Train Loss: 0.0030, Train Acc: 0.7238, Test Loss: 0.0048, Test Acc: 0.5918\n",
      "Epoch [29/50], Train Loss: 0.0030, Train Acc: 0.7310, Test Loss: 0.0048, Test Acc: 0.5914\n",
      "Epoch [30/50], Train Loss: 0.0029, Train Acc: 0.7389, Test Loss: 0.0049, Test Acc: 0.5909\n",
      "Epoch [31/50], Train Loss: 0.0028, Train Acc: 0.7434, Test Loss: 0.0048, Test Acc: 0.5942\n",
      "Epoch [32/50], Train Loss: 0.0027, Train Acc: 0.7508, Test Loss: 0.0049, Test Acc: 0.5933\n",
      "Epoch [33/50], Train Loss: 0.0027, Train Acc: 0.7557, Test Loss: 0.0049, Test Acc: 0.5948\n",
      "Epoch [34/50], Train Loss: 0.0026, Train Acc: 0.7638, Test Loss: 0.0050, Test Acc: 0.5924\n",
      "Epoch [35/50], Train Loss: 0.0025, Train Acc: 0.7684, Test Loss: 0.0050, Test Acc: 0.5967\n",
      "Epoch [36/50], Train Loss: 0.0025, Train Acc: 0.7742, Test Loss: 0.0050, Test Acc: 0.5997\n",
      "Epoch [37/50], Train Loss: 0.0024, Train Acc: 0.7795, Test Loss: 0.0051, Test Acc: 0.5983\n",
      "Epoch [38/50], Train Loss: 0.0023, Train Acc: 0.7814, Test Loss: 0.0051, Test Acc: 0.5969\n",
      "Epoch [39/50], Train Loss: 0.0023, Train Acc: 0.7899, Test Loss: 0.0051, Test Acc: 0.5946\n",
      "Epoch [40/50], Train Loss: 0.0022, Train Acc: 0.7960, Test Loss: 0.0052, Test Acc: 0.5922\n",
      "Epoch [41/50], Train Loss: 0.0022, Train Acc: 0.7986, Test Loss: 0.0053, Test Acc: 0.5916\n",
      "Epoch [42/50], Train Loss: 0.0021, Train Acc: 0.8039, Test Loss: 0.0053, Test Acc: 0.5885\n",
      "Epoch [43/50], Train Loss: 0.0021, Train Acc: 0.8056, Test Loss: 0.0053, Test Acc: 0.5966\n",
      "Epoch [44/50], Train Loss: 0.0020, Train Acc: 0.8141, Test Loss: 0.0053, Test Acc: 0.6015\n",
      "Epoch [45/50], Train Loss: 0.0020, Train Acc: 0.8155, Test Loss: 0.0054, Test Acc: 0.5977\n",
      "Epoch [46/50], Train Loss: 0.0020, Train Acc: 0.8190, Test Loss: 0.0054, Test Acc: 0.5951\n",
      "Epoch [47/50], Train Loss: 0.0019, Train Acc: 0.8263, Test Loss: 0.0055, Test Acc: 0.5953\n",
      "Epoch [48/50], Train Loss: 0.0019, Train Acc: 0.8268, Test Loss: 0.0055, Test Acc: 0.5982\n",
      "Epoch [49/50], Train Loss: 0.0018, Train Acc: 0.8328, Test Loss: 0.0056, Test Acc: 0.5934\n",
      "Epoch [50/50], Train Loss: 0.0018, Train Acc: 0.8344, Test Loss: 0.0055, Test Acc: 0.5904\n",
      "CPU times: user 4min 3s, sys: 1min 59s, total: 6min 2s\n",
      "Wall time: 6min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NUM_EPOCHS = 50\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    train_acc = 0\n",
    "    test_acc = 0\n",
    "    model.train()\n",
    "    for i, (data, label) in enumerate(trainLoader):\n",
    "        data = Variable(data.view(-1, 3072)).cuda()\n",
    "        label = Variable(label.view(-1)).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        _, predict = torch.max(output, 1)\n",
    "        num_correct = (predict == label).sum()\n",
    "        train_acc += num_correct.data[0]\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    for i, (data, label) in enumerate(testLoader):\n",
    "        data = Variable(data.view(-1, 3072)).cuda()\n",
    "        label = Variable(label.view(-1)).cuda()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        test_loss += loss.data[0]\n",
    "        _, predict = torch.max(output, 1)\n",
    "        num_correct = (predict == label).sum()\n",
    "        test_acc += num_correct.data[0]\n",
    "        \n",
    "    print('Epoch [%d/%d], Train Loss: %.4f, Train Acc: %.4f, Test Loss: %.4f, Test Acc: %.4f'\n",
    "            %(epoch+1, NUM_EPOCHS, \n",
    "              train_loss / NUM_TRAIN, train_acc / NUM_TRAIN, \n",
    "              test_loss / NUM_TEST, test_acc / NUM_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
